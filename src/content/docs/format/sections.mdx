---
title: Skill Sections
description: The standard sections in a generated skill and what each one does
---

import { Aside } from '@astrojs/starlight/components';

Every skill generated by SkillThis contains up to five standard sections. Each serves a distinct purpose in teaching the AI your methodology.

## Quick Start

**Purpose:** Immediate, actionable value with no preamble.

The Quick Start is the first thing the AI reads after the frontmatter. It should provide an immediately usable example or a concise summary of the core workflow.

**Good Quick Start:**
```markdown
## Quick Start

Given a pull request, evaluate it in this order:

1. Read the PR description and linked issue
2. Check for security issues (injection, auth bypass, data exposure)
3. Review performance implications (N+1 queries, missing indexes)
4. Verify error handling and edge cases
5. Suggest improvements with specific line references
```

**Bad Quick Start:**
```markdown
## Quick Start

Code review is an important part of the software development
lifecycle. It helps maintain code quality and catch bugs early.
In this skill, we'll cover how to review code effectively...
```

The bad version wastes tokens on preamble. The AI already knows what code review is.

<Aside>
  Missing a Quick Start section costs 15 points on the grading rubric. Always lead with action.
</Aside>

## Workflow

**Purpose:** Step-by-step process with clear ordering.

The Workflow section breaks down your methodology into sequential steps. For complex workflows, include a checklist:

```markdown
## Workflow

### Phase 1: Discovery
1. Read the customer's current tech stack documentation
2. Identify likely pain points based on stack analysis
3. Build a custom demo environment mirroring their setup

### Phase 2: Presentation
1. Open with discovery questions (5-10 minutes)
2. Demo only the 3-4 features that solve their specific problems
3. Leave 15 minutes for hands-on exploration

### Phase 3: Follow-up
1. Send personalized Loom walkthrough within 24 hours
2. Include specific configuration for their use case
3. Schedule technical deep-dive if interest confirmed

Progress Checklist:
- [ ] Discovery research complete
- [ ] Demo environment built
- [ ] Presentation delivered
- [ ] Follow-up sent
```

Checklists are especially valuable for complex multi-step workflows where the AI needs to track progress.

## Examples

**Purpose:** Concrete input/output pairs showing the skill in action.

Examples are the most heavily weighted section (20% of the grade). They must be concrete, not abstract.

**Good examples (concrete input/output):**
```markdown
## Examples

**Example 1: API Endpoint Review**
Input: PR adds a new `/api/users/:id` DELETE endpoint
Output:
- Flag: No authentication check on delete operation
- Flag: Missing rate limiting
- Suggestion: Add soft-delete with `deleted_at` timestamp instead of hard delete
- Suggestion: Return 204 No Content, not 200 with body

**Example 2: Database Migration**
Input: PR adds a new index on `orders.customer_id`
Output:
- Approve: Index matches the N+1 query pattern in `OrderService`
- Note: Consider adding `CONCURRENTLY` for zero-downtime on production
- Note: Estimated build time ~30 seconds for current table size
```

**Bad examples (abstract):**
```markdown
## Examples

When reviewing code, look for common issues like security
vulnerabilities, performance problems, and maintainability
concerns. A good review catches bugs before they reach production.
```

The bad version describes what to do rather than showing a real case.

## Best Practices

**Purpose:** Guidelines, tips, and recommended approaches.

This section captures the wisdom that comes from experience. Keep entries specific and actionable.

```markdown
## Best Practices

- Always prep candidates before interviews (reduces no-shows by 40%)
- Debrief hiring managers same-day while impressions are fresh
- Use the "soft close" approach: help candidates decide, never hard sell
- Build relationships even with rejected candidates (future pipeline)
- Track all interactions in ATS for pipeline analytics
```

Each item should be a concrete action, not an abstract principle.

## Common Pitfalls

**Purpose:** What NOT to do, common mistakes to avoid.

Pitfalls act as guardrails, preventing the AI from making the same mistakes humans commonly make.

```markdown
## Common Pitfalls

- Screening for keywords instead of capability (filters out strong candidates)
- Skipping the motivation check (leads to early attrition)
- Not calibrating with the hiring manager on what "senior" means
- Sending generic outreach messages (response rate drops 60%)
- Waiting until offer stage to discuss compensation expectations
```

## Section Order

The standard order is:

1. Quick Start (immediate value)
2. Workflow (detailed process)
3. Examples (concrete demonstrations)
4. Best Practices (guidelines)
5. Common Pitfalls (guardrails)

Not all sections are required. A skill focused on a simple process might only need Quick Start, Workflow, and Examples.

## Length Guidelines

The entire skill body should target approximately 500 lines maximum. If it's longer, consider:

- Cutting verbose explanations (the AI is smart, don't over-explain)
- Removing obvious advice
- Providing defaults instead of listing many options
- Splitting into separate files for advanced features (when using Claude Code)
